{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e8a625e",
   "metadata": {},
   "source": [
    "# 01 Data Collection — Raw Data Archive (v1.0.0)\n",
    "\n",
    "## Purpose\n",
    "Scrape LinkedIn job listings and extract raw metadata with maximum fidelity. Build immutable, reproducible datasets suitable for downstream preprocessing and analysis.\n",
    "\n",
    "## Pipeline (v1.0.0 — Raw Only)\n",
    "Frozen architecture with no parsing or normalization:\n",
    "1. **Phase 1 — Listing Scrape**: Fetch job cards (title, company, location, link, company URL) with exponential backoff\n",
    "2. **Phase 2 — Detail Extraction**: Visit each job page → extract full description (raw text + HTML), insight panel, salary, applicant count, easy apply flags, seniority/industry/function/type fields, embedded JSON-LD\n",
    "3. **Phase 3 — Company Pages** *(optional)*: Visit company about pages (deduplicated) → extract about section (text + HTML), industry, size, HQ, type, specialties\n",
    "4. **Phase 4 — Save Raw Data**: Immutable archive to `data/raw/jobs/` and `data/raw/companies/` with v1.0.0 schema\n",
    "\n",
    "## Schema & Formats\n",
    "- **Job Records**: Nested JSON with sections: scrape_metadata, job_identity, job_card_raw, job_page_raw (30+ fields), company_info, quality_tracking, hashing\n",
    "- **Company Records**: Nested JSON with sections: company_identity, company_page_raw, hashing, timestamps, quality_tracking\n",
    "- **Storage**: JSON files with content SHA-256 hashing for change detection\n",
    "- **Versions**: `SCRAPER_VERSION=\"1.0.0\"`, `RAW_SCHEMA_VERSION=\"1.0.0\"` (frozen)\n",
    "\n",
    "## IO\n",
    "- **Input**: Search parameters (keywords, location, limit)\n",
    "- **Output (Raw Jobs)**: `data/raw/linkedin_raw_jobs_<timestamp>.json`\n",
    "- **Output (Raw Companies)**: `data/raw/linkedin_raw_companies_<timestamp>.json` \n",
    "- **Reports**: `outputs/tables/scrape_report_*.json`, `outputs/logs/scrape_*.log`\n",
    "\n",
    "## Key Features\n",
    "- **Exponential backoff** on 429 rate limits (2^attempt formula with randomization)\n",
    "- **Content hashing** for deduplication and change detection (SHA-256)\n",
    "- **Interim checkpointing** (saves every 10 records to prevent data loss)\n",
    "- **Quality tracking** (high/medium/low extraction quality ratings)\n",
    "- **Company deduplication** (one fetch per unique company, caching)\n",
    "- **Frozen schema** (immutable v1.0.0 for reproducibility)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e52965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraper version: 1.0.0\n",
      "Raw schema version: 1.0.0\n",
      "Pipeline: Raw-Only Mode (v1.0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "# Ensure the project root is on the path so `src.*` imports work\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import pyarrow # For efficient Parquet handling (future)\n",
    "\n",
    "# Project modules\n",
    "from src.scraping.linkedin_scraper import LinkedInScraper\n",
    "from src.scraping.raw_schema_v1 import SCRAPER_VERSION, RAW_SCHEMA_VERSION\n",
    "from src.pipeline import (\n",
    "    setup_logging,\n",
    "    run_pipeline,\n",
    "    save_scrape_report,\n",
    ")\n",
    "\n",
    "# Ensure output directories exist\n",
    "for d in [\"../data/raw\", \"../data/raw/jobs\", \"../data/raw/companies\", \n",
    "          \"../data/raw/crawl_logs\", \"../outputs/logs\", \"../outputs/tables\"]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(f\"Scraper version: {SCRAPER_VERSION}\")\n",
    "print(f\"Raw schema version: {RAW_SCHEMA_VERSION}\")\n",
    "print(f\"Pipeline: Raw-Only Mode (v1.0.0)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c396d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "Set search parameters and scraping options. Keep `LIMIT` at 20–30 during development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4182f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected keyword: 'Data Scientist' (index 0)\n",
      "Location: 'worldwide' | Limit: 100\n",
      "Company pages: False | Raw Schema v1.0.0\n"
     ]
    }
   ],
   "source": [
    "# ── Search keywords (select one per run) ──\n",
    "KEYWORDS_LIST = [ \n",
    "    # Data Science / Core Roles\n",
    "    \"Data Scientist\",            # 0\n",
    "    \"Machine Learning Engineer\", # 1\n",
    "    \"AI Engineer\",               # 2\n",
    "    \"Deep Learning Engineer\",    # 3\n",
    "    \"Applied Data Scientist\",    # 4\n",
    "    \"Research Scientist\",        # 5\n",
    "    \"Data Analyst\",              # 6\n",
    "    \"Business Intelligence Analyst\", # 7\n",
    "    # GenAI / LLM / Emerging AI\n",
    "    \"Generative AI Engineer\",    # 8\n",
    "    \"LLM Engineer\",              # 9\n",
    "    \"Prompt Engineer\",           # 10\n",
    "    \"NLP Engineer\",              # 11\n",
    "    \"Large Language Models Engineer\", # 12\n",
    "    \"AI Researcher\",             # 13\n",
    "    # Data / Analytics Infrastructure\n",
    "    \"Data Engineer\",             # 14\n",
    "    \"ML Ops Engineer\",           # 15\n",
    "    \"MLOps Engineer\",            # 16\n",
    "    \"AI Infrastructure Engineer\", # 17\n",
    "    \"Data Platform Engineer\",    # 18\n",
    "    \"ETL Engineer\",              # 19\n",
    "    # Specialized / Advanced Roles\n",
    "    \"Computer Vision Engineer\",  # 20\n",
    "    \"Robotics Engineer\",         # 21\n",
    "    \"Forecasting Analyst\",       # 22\n",
    "    \"Quantitative Analyst\",      # 23\n",
    "    \"Research Engineer\",         # 24\n",
    "    # Internships / Entry-Level\n",
    "    \"Data Science Intern\",       # 25\n",
    "    \"ML Intern\",                 # 26\n",
    "    \"AI Intern\",                 # 27\n",
    "    \"Data Analyst Intern\",       # 28\n",
    "]\n",
    "\n",
    "# Select keyword by index (0 = \"Data Scientist\", 1 = \"Machine Learning Engineer\", etc.)\n",
    "KEYWORD_INDEX = 0\n",
    "KEYWORDS = KEYWORDS_LIST[KEYWORD_INDEX]\n",
    "\n",
    "# ── Other search parameters ──\n",
    "LOCATION = \"\"          # Empty = worldwide\n",
    "LIMIT = 100             # Keep at 20-30 for dev; scale later\n",
    "\n",
    "# ── Scraping options ──\n",
    "SCRAPE_COMPANY_PAGES = False   # Visit company about pages (deduplicated)\n",
    "\n",
    "# ── Output paths (use project root for absolute path) ──\n",
    "RAW_OUTPUT_DIR = os.path.join(project_root, \"data/raw/jobs\")\n",
    "\n",
    "print(f\"Selected keyword: '{KEYWORDS}' (index {KEYWORD_INDEX})\")\n",
    "print(f\"Location: '{LOCATION or 'worldwide'}' | Limit: {LIMIT}\")\n",
    "print(f\"Company pages: {SCRAPE_COMPANY_PAGES} | Raw Schema v1.0.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d91ad6",
   "metadata": {},
   "source": [
    "## Run Pipeline (v1.0.0 — Raw Only)\n",
    "Execute the raw data collection pipeline. No parsing or normalization is performed.\n",
    "\n",
    "**Process:**\n",
    "1. **Phase 1**: Fetch job listings from LinkedIn search\n",
    "2. **Phase 2**: Visit each job detail page → extract full raw fields\n",
    "3. **Phase 3** (optional): Fetch company about pages if `SCRAPE_COMPANY_PAGES=True`\n",
    "4. **Save**: Raw JSON with v1.0.0 schema to `data/raw/`\n",
    "\n",
    "Output records include all raw field values, content hashing, extraction quality metrics, and metadata for reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91597213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-16 20:34:39,609 | INFO    | src.pipeline | ============================================================\n",
      "2026-02-16 20:34:39,611 | INFO    | src.pipeline | TOP APPLICANT — Data Collection Pipeline v1.0.0\n",
      "2026-02-16 20:34:39,612 | INFO    | src.pipeline | Raw Schema Version: 1.0.0\n",
      "2026-02-16 20:34:39,612 | INFO    | src.pipeline | Scraper Version: 1.0.0\n",
      "2026-02-16 20:34:39,613 | INFO    | src.pipeline | Search: 'Data Scientist' | Location: '' | Limit: 100\n",
      "2026-02-16 20:34:39,615 | INFO    | src.pipeline | Mode: Raw Data Collection Only (No Parsing)\n",
      "2026-02-16 20:34:39,616 | INFO    | src.pipeline | ============================================================\n",
      "2026-02-16 20:34:39,619 | INFO    | src.scraping.linkedin_scraper | Loaded 0 existing job IDs to skip.\n",
      "2026-02-16 20:34:39,620 | INFO    | src.scraping.linkedin_scraper | Phase 1: Scraping up to 100 listings for 'Data Scientist' in ''\n",
      "2026-02-16 20:34:41,481 | INFO    | src.scraping.linkedin_scraper |   [1] Data Scientist Intern @ Tinder\n",
      "2026-02-16 20:34:43,782 | INFO    | src.scraping.linkedin_scraper |   [2] Data Scientist II, Growth @ Tinder\n",
      "2026-02-16 20:34:43,783 | INFO    | src.scraping.linkedin_scraper |   [3] Data Scientist (Entry-Level) @ Why Hiring\n",
      "2026-02-16 20:34:43,783 | INFO    | src.scraping.linkedin_scraper |   [4] Sr. Staff Data Scientist - LinkedIn Premium @ LinkedIn\n",
      "2026-02-16 20:34:43,785 | INFO    | src.scraping.linkedin_scraper |   [5] Machine Learning Engineer (L4) - Production Science @ Netflix\n",
      "2026-02-16 20:34:43,786 | INFO    | src.scraping.linkedin_scraper |   [6] Data Scientist @ Intero Integrity\n",
      "2026-02-16 20:34:43,786 | INFO    | src.scraping.linkedin_scraper |   [7] Research Scientist @ Aditi Consulting\n",
      "2026-02-16 20:34:43,787 | INFO    | src.scraping.linkedin_scraper |   [8] Research Data Scientist @ University of Notre Dame\n",
      "2026-02-16 20:34:43,788 | INFO    | src.scraping.linkedin_scraper |   [9] Research Scientist, Google Cloud AI @ Google\n",
      "2026-02-16 20:34:43,789 | INFO    | src.scraping.linkedin_scraper |   [10] Data Scientist @ Two Sigma\n",
      "2026-02-16 20:34:43,791 | INFO    | src.scraping.linkedin_scraper |   [11] Data Scientist @ Veracity Software Inc\n",
      "2026-02-16 20:34:45,812 | INFO    | src.scraping.linkedin_scraper |   [12] Junior Data Scientist @ Wpromote\n",
      "2026-02-16 20:34:45,813 | INFO    | src.scraping.linkedin_scraper |   [13] Staff Data Scientist @ LinkedIn\n",
      "2026-02-16 20:34:45,814 | INFO    | src.scraping.linkedin_scraper |   [14] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:45,815 | INFO    | src.scraping.linkedin_scraper |   [15] Data Scientist @ System One\n",
      "2026-02-16 20:34:45,816 | INFO    | src.scraping.linkedin_scraper |   [16] Data Scientist @ PMMC\n",
      "2026-02-16 20:34:45,818 | INFO    | src.scraping.linkedin_scraper |   [17] Staff Research Scientist @ Waffle Labs\n",
      "2026-02-16 20:34:45,819 | INFO    | src.scraping.linkedin_scraper |   [18] Data Scientist @ Milestone Technologies, Inc.\n",
      "2026-02-16 20:34:45,820 | INFO    | src.scraping.linkedin_scraper |   [19] Data Scientist - Fraud @ Plaid\n",
      "2026-02-16 20:34:45,821 | INFO    | src.scraping.linkedin_scraper |   [20] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:45,822 | INFO    | src.scraping.linkedin_scraper |   [21] Senior Data Scientist @ Roku\n",
      "2026-02-16 20:34:47,819 | INFO    | src.scraping.linkedin_scraper |   [22] Machine Learning Engineer @ LHH\n",
      "2026-02-16 20:34:47,820 | INFO    | src.scraping.linkedin_scraper |   [23] Data Scientist, Lifecycle Marketing @ Wealthfront\n",
      "2026-02-16 20:34:47,821 | INFO    | src.scraping.linkedin_scraper |   [24] Data Scientist - Strategic Data Solutions @ Apple\n",
      "2026-02-16 20:34:47,823 | INFO    | src.scraping.linkedin_scraper |   [25] Data Scientist @ Quevera\n",
      "2026-02-16 20:34:47,824 | INFO    | src.scraping.linkedin_scraper |   [26] Associate Data Scientist @ Tubi\n",
      "2026-02-16 20:34:47,826 | INFO    | src.scraping.linkedin_scraper |   [27] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:47,828 | INFO    | src.scraping.linkedin_scraper |   [28] Data Scientist @ TalentOla\n",
      "2026-02-16 20:34:47,829 | INFO    | src.scraping.linkedin_scraper |   [29] Data Scientist @ Juul Labs\n",
      "2026-02-16 20:34:47,831 | INFO    | src.scraping.linkedin_scraper |   [30] Data Scientist @ Kinect\n",
      "2026-02-16 20:34:47,832 | INFO    | src.scraping.linkedin_scraper |   [31] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:50,181 | INFO    | src.scraping.linkedin_scraper |   [32] Data Scientist @ FanDuel\n",
      "2026-02-16 20:34:50,182 | INFO    | src.scraping.linkedin_scraper |   [33] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:50,183 | INFO    | src.scraping.linkedin_scraper |   [34] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:50,185 | INFO    | src.scraping.linkedin_scraper |   [35] Staff Data Scientist, Marketing @ Asana\n",
      "2026-02-16 20:34:50,187 | INFO    | src.scraping.linkedin_scraper |   [36] Data Scientist @ Meta\n",
      "2026-02-16 20:34:50,188 | INFO    | src.scraping.linkedin_scraper |   [37] Data Scientist - AI Decision Intelligence Platform @ Andiamo\n",
      "2026-02-16 20:34:50,190 | INFO    | src.scraping.linkedin_scraper |   [38] Data Scientist, PAR @ Meta\n",
      "2026-02-16 20:34:50,191 | INFO    | src.scraping.linkedin_scraper |   [39] Data Scientist | $90 Remote @ Crossing Hurdles\n",
      "2026-02-16 20:34:50,193 | INFO    | src.scraping.linkedin_scraper |   [40] Data Scientist - Data-Driven Global Investment Firm @ Andiamo\n",
      "2026-02-16 20:34:50,194 | INFO    | src.scraping.linkedin_scraper |   [41] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:52,444 | INFO    | src.scraping.linkedin_scraper |   [42] Data Scientist @ Swoon\n",
      "2026-02-16 20:34:52,445 | INFO    | src.scraping.linkedin_scraper |   [43] Data Scientist @ Fractal\n",
      "2026-02-16 20:34:52,446 | INFO    | src.scraping.linkedin_scraper |   [44] Data Scientist, Product @ Robinhood\n",
      "2026-02-16 20:34:52,448 | INFO    | src.scraping.linkedin_scraper |   [45] Data Scientist, Handshake AI @ Handshake\n",
      "2026-02-16 20:34:52,449 | INFO    | src.scraping.linkedin_scraper |   [46] Junior Data Scientist @ Brooksource\n",
      "2026-02-16 20:34:52,449 | INFO    | src.scraping.linkedin_scraper |   [47] Data Scientist / Analytics Engineer @ Clarity Cubed\n",
      "2026-02-16 20:34:52,451 | INFO    | src.scraping.linkedin_scraper |   [48] Data Scientist @ Zywave\n",
      "2026-02-16 20:34:52,452 | INFO    | src.scraping.linkedin_scraper |   [49] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:52,454 | INFO    | src.scraping.linkedin_scraper |   [50] Senior Data Scientist @ Roku\n",
      "2026-02-16 20:34:52,456 | INFO    | src.scraping.linkedin_scraper |   [51] Data Scientist I @ Oscar Health\n",
      "2026-02-16 20:34:54,782 | INFO    | src.scraping.linkedin_scraper |   [52] Data Scientist - Junior @ Vantor\n",
      "2026-02-16 20:34:54,783 | INFO    | src.scraping.linkedin_scraper |   [53] Data Scientist L6 - Games Portfolio @ Netflix\n",
      "2026-02-16 20:34:54,783 | INFO    | src.scraping.linkedin_scraper |   [54] Associate Data Scientist - Marketing @ Bumble Inc.\n",
      "2026-02-16 20:34:54,784 | INFO    | src.scraping.linkedin_scraper |   [55] Data Scientist @ Dropbox\n",
      "2026-02-16 20:34:54,785 | INFO    | src.scraping.linkedin_scraper |   [56] Research Scientist – Multi-modal Sensing AI @ Bosch USA\n",
      "2026-02-16 20:34:54,787 | INFO    | src.scraping.linkedin_scraper |   [57] Data Scientist, Algorithms @ Lyft\n",
      "2026-02-16 20:34:54,788 | INFO    | src.scraping.linkedin_scraper |   [58] Data Scientist - Fraud @ Plaid\n",
      "2026-02-16 20:34:54,790 | INFO    | src.scraping.linkedin_scraper |   [59] Data Scientist/Analyst @ Selby Jennings\n",
      "2026-02-16 20:34:54,791 | INFO    | src.scraping.linkedin_scraper |   [60] Data Scientist, Algorithms, Optimization - Fulfillment @ Lyft\n",
      "2026-02-16 20:34:54,793 | INFO    | src.scraping.linkedin_scraper |   [61] Data Scientist @ Sprouts Farmers Market\n",
      "2026-02-16 20:34:56,922 | INFO    | src.scraping.linkedin_scraper |   [62] Data Scientist @ Boston VA Research Institute, Inc. (BVARI)\n",
      "2026-02-16 20:34:56,923 | INFO    | src.scraping.linkedin_scraper |   [63] Machine Learning Engineer Intern, (MS/PhD) 2026 @ Netflix\n",
      "2026-02-16 20:34:56,924 | INFO    | src.scraping.linkedin_scraper |   [64] Data Scientist, Product Analytics @ Meta\n",
      "2026-02-16 20:34:56,925 | INFO    | src.scraping.linkedin_scraper |   [65] Data Scientist @ ValidiFI\n",
      "2026-02-16 20:34:56,926 | INFO    | src.scraping.linkedin_scraper |   [66] Data Scientist, Strategic Intelligence & Risk @ OpenAI\n",
      "2026-02-16 20:34:56,929 | INFO    | src.scraping.linkedin_scraper |   [67] Data Scientist @ DW SISTERS LLC\n",
      "2026-02-16 20:34:56,930 | INFO    | src.scraping.linkedin_scraper |   [68] Data Scientist (REMOTE) @ Lensa\n",
      "2026-02-16 20:34:56,931 | INFO    | src.scraping.linkedin_scraper |   [69] Data Scientist @ Wpromote\n",
      "2026-02-16 20:34:56,933 | INFO    | src.scraping.linkedin_scraper |   [70] Data Scientist @ Boston VA Research Institute, Inc. (BVARI)\n",
      "2026-02-16 20:34:56,934 | INFO    | src.scraping.linkedin_scraper |   [71] Staff Data Scientist, Marketing @ Asana\n",
      "2026-02-16 20:34:59,374 | INFO    | src.scraping.linkedin_scraper |   [72] Data Scientist @ Kforce Inc\n",
      "2026-02-16 20:34:59,375 | INFO    | src.scraping.linkedin_scraper |   [73] Data Scientist I @ Worldpay\n",
      "2026-02-16 20:34:59,376 | INFO    | src.scraping.linkedin_scraper |   [74] Data Scientist @ Alexander Chapman\n",
      "2026-02-16 20:34:59,377 | INFO    | src.scraping.linkedin_scraper |   [75] Business Data Scientist, Google Cloud Security Strategy @ Google\n",
      "2026-02-16 20:34:59,379 | INFO    | src.scraping.linkedin_scraper |   [76] Product Data Scientist @ AvePoint\n",
      "2026-02-16 20:34:59,381 | INFO    | src.scraping.linkedin_scraper |   [77] Data Scientist @ Citadel Securities\n",
      "2026-02-16 20:34:59,381 | INFO    | src.scraping.linkedin_scraper |   [78] Director, Data Scientist (Predictive & Agentic AI) @ SymphonyAI\n",
      "2026-02-16 20:34:59,382 | INFO    | src.scraping.linkedin_scraper |   [79] Data Scientist, Product, Education, Data Science @ Google\n",
      "2026-02-16 20:34:59,384 | INFO    | src.scraping.linkedin_scraper |   [80] Data Scientist @ Eleve Talent\n",
      "2026-02-16 20:34:59,386 | INFO    | src.scraping.linkedin_scraper |   [81] Data Scientist @ Curate Partners\n",
      "2026-02-16 20:35:02,041 | INFO    | src.scraping.linkedin_scraper |   [82] Senior Data Scientist @ HireTalent - Staffing & Recruiting Firm\n",
      "2026-02-16 20:35:02,042 | INFO    | src.scraping.linkedin_scraper |   [83] Data Scientist @ CSG Talent\n",
      "2026-02-16 20:35:02,043 | INFO    | src.scraping.linkedin_scraper |   [84] Data Scientist, Marketing @ OpenAI\n",
      "2026-02-16 20:35:02,044 | INFO    | src.scraping.linkedin_scraper |   [85] Data Scientist, Subscription Analytics @ Apple\n",
      "2026-02-16 20:35:02,045 | INFO    | src.scraping.linkedin_scraper |   [86] Data Scientist @ Opendoor\n",
      "2026-02-16 20:35:02,048 | INFO    | src.scraping.linkedin_scraper |   [87] Data Scientist - 994 @ Lightcast\n",
      "2026-02-16 20:35:02,050 | INFO    | src.scraping.linkedin_scraper |   [88] Data Scientist II @ Esri\n",
      "2026-02-16 20:35:02,051 | INFO    | src.scraping.linkedin_scraper |   [89] Data Scientist, Marketing @ OpenAI\n",
      "2026-02-16 20:35:02,052 | INFO    | src.scraping.linkedin_scraper |   [90] Data Scientist @ SkyBridge Aviation\n",
      "2026-02-16 20:35:02,053 | INFO    | src.scraping.linkedin_scraper |   [91] Data Scientist @ IntePros\n",
      "2026-02-16 20:35:04,912 | INFO    | src.scraping.linkedin_scraper |   [92] Data Scientist, Level 4 @ Snap Inc.\n",
      "2026-02-16 20:35:04,912 | INFO    | src.scraping.linkedin_scraper |   [93] Data Scientist @ Pathpoint\n",
      "2026-02-16 20:35:04,914 | INFO    | src.scraping.linkedin_scraper |   [94] Data Scientist - Drilling - Global Energy Tech Company @ Andiamo\n",
      "2026-02-16 20:35:04,916 | INFO    | src.scraping.linkedin_scraper |   [95] Data Scientist @ SoTalent\n",
      "2026-02-16 20:35:04,917 | INFO    | src.scraping.linkedin_scraper |   [96] Data Scientist @ Mantra Health\n",
      "2026-02-16 20:35:04,918 | INFO    | src.scraping.linkedin_scraper |   [97] Data Scientist Intern (TikTok-Product-Data Science)-2026 Summer (BS/MS) @ TikTok\n",
      "2026-02-16 20:35:04,919 | INFO    | src.scraping.linkedin_scraper |   [98] Machine Learning Engineer - ML infra @ Impax Recruitment\n",
      "2026-02-16 20:35:04,921 | INFO    | src.scraping.linkedin_scraper |   [99] Full Stack & Machine Learning Engineer @ Statt\n",
      "2026-02-16 20:35:04,922 | INFO    | src.scraping.linkedin_scraper |   [100] Senior Data Scientist – TechOps Predictive Engineering @ Delta Air Lines\n",
      "2026-02-16 20:35:05,860 | INFO    | src.scraping.linkedin_scraper | Phase 1 complete: 100 listings scraped.\n",
      "2026-02-16 20:35:05,862 | INFO    | src.scraping.linkedin_scraper | Phase 2: Extracting 100 job detail pages\n",
      "2026-02-16 20:35:05,864 | INFO    | src.scraping.linkedin_scraper |   [1/100] https://www.linkedin.com/jobs/view/data-scientist-intern-at-tinder-4323761210\n",
      "2026-02-16 20:35:09,520 | INFO    | src.scraping.linkedin_scraper |   [2/100] https://www.linkedin.com/jobs/view/data-scientist-ii-growth-at-tinder-4329686163\n",
      "2026-02-16 20:35:12,834 | INFO    | src.scraping.linkedin_scraper |   [3/100] https://www.linkedin.com/jobs/view/data-scientist-entry-level-at-why-hiring-4364763854\n",
      "2026-02-16 20:35:15,839 | INFO    | src.scraping.linkedin_scraper |   [4/100] https://www.linkedin.com/jobs/view/sr-staff-data-scientist-linkedin-premium-at-linkedin-4370805389\n",
      "2026-02-16 20:35:18,812 | INFO    | src.scraping.linkedin_scraper |   [5/100] https://www.linkedin.com/jobs/view/machine-learning-engineer-l4-production-science-at-netflix-4340536132\n",
      "2026-02-16 20:35:21,224 | INFO    | src.scraping.linkedin_scraper |   [6/100] https://www.linkedin.com/jobs/view/data-scientist-at-intero-integrity-4370710496\n",
      "2026-02-16 20:35:25,130 | INFO    | src.scraping.linkedin_scraper |   [7/100] https://www.linkedin.com/jobs/view/research-scientist-at-aditi-consulting-4371060464\n",
      "2026-02-16 20:35:27,940 | INFO    | src.scraping.linkedin_scraper |   [8/100] https://www.linkedin.com/jobs/view/research-data-scientist-at-university-of-notre-dame-4363092602\n",
      "2026-02-16 20:35:30,547 | INFO    | src.scraping.linkedin_scraper |   [9/100] https://www.linkedin.com/jobs/view/research-scientist-google-cloud-ai-at-google-4370401361\n",
      "2026-02-16 20:35:33,595 | INFO    | src.scraping.linkedin_scraper |   [10/100] https://www.linkedin.com/jobs/view/data-scientist-at-two-sigma-4209153448\n",
      "2026-02-16 20:35:36,021 | INFO    | src.scraping.linkedin_scraper |   [11/100] https://www.linkedin.com/jobs/view/data-scientist-at-veracity-software-inc-4363030158\n",
      "2026-02-16 20:35:40,075 | INFO    | src.scraping.linkedin_scraper |   [12/100] https://www.linkedin.com/jobs/view/junior-data-scientist-at-wpromote-4372795503\n",
      "2026-02-16 20:35:42,657 | INFO    | src.scraping.linkedin_scraper |   [13/100] https://www.linkedin.com/jobs/view/staff-data-scientist-at-linkedin-4365223573\n",
      "2026-02-16 20:35:46,253 | INFO    | src.scraping.linkedin_scraper |   [14/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120819992\n",
      "2026-02-16 20:35:48,868 | INFO    | src.scraping.linkedin_scraper |   [15/100] https://www.linkedin.com/jobs/view/data-scientist-at-system-one-4370995947\n",
      "2026-02-16 20:35:51,549 | INFO    | src.scraping.linkedin_scraper |   [16/100] https://www.linkedin.com/jobs/view/data-scientist-at-pmmc-4370453511\n",
      "2026-02-16 20:35:54,887 | INFO    | src.scraping.linkedin_scraper |   [17/100] https://www.linkedin.com/jobs/view/staff-research-scientist-at-waffle-labs-4370537750\n",
      "2026-02-16 20:35:59,121 | INFO    | src.scraping.linkedin_scraper |   [18/100] https://www.linkedin.com/jobs/view/data-scientist-at-milestone-technologies-inc-4370725357\n",
      "2026-02-16 20:36:01,734 | INFO    | src.scraping.linkedin_scraper |   [19/100] https://www.linkedin.com/jobs/view/data-scientist-fraud-at-plaid-4337023291\n",
      "2026-02-16 20:36:06,878 | INFO    | src.scraping.linkedin_scraper |   [20/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120823523\n",
      "2026-02-16 20:36:10,043 | INFO    | src.scraping.linkedin_scraper |   [21/100] https://www.linkedin.com/jobs/view/senior-data-scientist-at-roku-4372103052\n",
      "2026-02-16 20:36:14,380 | INFO    | src.scraping.linkedin_scraper |   [22/100] https://www.linkedin.com/jobs/view/machine-learning-engineer-at-lhh-4371052774\n",
      "2026-02-16 20:36:19,274 | INFO    | src.scraping.linkedin_scraper |   [23/100] https://www.linkedin.com/jobs/view/data-scientist-lifecycle-marketing-at-wealthfront-4330764625\n",
      "2026-02-16 20:36:22,547 | INFO    | src.scraping.linkedin_scraper |   [24/100] https://www.linkedin.com/jobs/view/data-scientist-strategic-data-solutions-at-apple-4371556780\n",
      "2026-02-16 20:36:25,682 | INFO    | src.scraping.linkedin_scraper |   [25/100] https://www.linkedin.com/jobs/view/data-scientist-at-quevera-4370898893\n",
      "2026-02-16 20:36:28,675 | INFO    | src.scraping.linkedin_scraper |   [26/100] https://www.linkedin.com/jobs/view/associate-data-scientist-at-tubi-4367368175\n",
      "2026-02-16 20:36:31,465 | INFO    | src.scraping.linkedin_scraper |   [27/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120828049\n",
      "2026-02-16 20:36:34,534 | INFO    | src.scraping.linkedin_scraper |   [28/100] https://www.linkedin.com/jobs/view/data-scientist-at-talentola-4370448205\n",
      "2026-02-16 20:36:37,605 | INFO    | src.scraping.linkedin_scraper |   [29/100] https://www.linkedin.com/jobs/view/data-scientist-at-juul-labs-4344769602\n",
      "2026-02-16 20:36:40,255 | INFO    | src.scraping.linkedin_scraper |   [30/100] https://www.linkedin.com/jobs/view/data-scientist-at-kinect-4370029551\n",
      "2026-02-16 20:36:43,063 | INFO    | src.scraping.linkedin_scraper |   [31/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4166293040\n",
      "2026-02-16 20:36:46,077 | INFO    | src.scraping.linkedin_scraper |   [32/100] https://www.linkedin.com/jobs/view/data-scientist-at-fanduel-4349823783\n",
      "2026-02-16 20:36:48,793 | INFO    | src.scraping.linkedin_scraper |   [33/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120822583\n",
      "2026-02-16 20:36:51,713 | INFO    | src.scraping.linkedin_scraper |   [34/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120824514\n",
      "2026-02-16 20:36:54,874 | INFO    | src.scraping.linkedin_scraper |   [35/100] https://www.linkedin.com/jobs/view/staff-data-scientist-marketing-at-asana-4363954806\n",
      "2026-02-16 20:36:57,892 | INFO    | src.scraping.linkedin_scraper |   [36/100] https://www.linkedin.com/jobs/view/data-scientist-at-meta-4345925035\n",
      "2026-02-16 20:37:00,596 | INFO    | src.scraping.linkedin_scraper |   [37/100] https://www.linkedin.com/jobs/view/data-scientist-ai-decision-intelligence-platform-at-andiamo-4364053807\n",
      "2026-02-16 20:37:03,535 | INFO    | src.scraping.linkedin_scraper |   [38/100] https://www.linkedin.com/jobs/view/data-scientist-par-at-meta-4356518401\n",
      "2026-02-16 20:37:05,830 | INFO    | src.scraping.linkedin_scraper |   [39/100] https://www.linkedin.com/jobs/view/data-scientist-%2490-remote-at-crossing-hurdles-4372006407\n",
      "2026-02-16 20:37:08,298 | INFO    | src.scraping.linkedin_scraper |   [40/100] https://www.linkedin.com/jobs/view/data-scientist-data-driven-global-investment-firm-at-andiamo-4306629597\n",
      "2026-02-16 20:37:11,237 | INFO    | src.scraping.linkedin_scraper |   [41/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120824556\n",
      "2026-02-16 20:37:14,456 | INFO    | src.scraping.linkedin_scraper |   [42/100] https://www.linkedin.com/jobs/view/data-scientist-at-swoon-4367244753\n",
      "2026-02-16 20:37:17,552 | INFO    | src.scraping.linkedin_scraper |   [43/100] https://www.linkedin.com/jobs/view/data-scientist-at-fractal-4368226729\n",
      "2026-02-16 20:37:20,445 | INFO    | src.scraping.linkedin_scraper |   [44/100] https://www.linkedin.com/jobs/view/data-scientist-product-at-robinhood-4355431958\n",
      "2026-02-16 20:37:23,627 | INFO    | src.scraping.linkedin_scraper |   [45/100] https://www.linkedin.com/jobs/view/data-scientist-handshake-ai-at-handshake-4365557225\n",
      "2026-02-16 20:37:27,349 | INFO    | src.scraping.linkedin_scraper |   [46/100] https://www.linkedin.com/jobs/view/junior-data-scientist-at-brooksource-4368272855\n",
      "2026-02-16 20:37:29,536 | INFO    | src.scraping.linkedin_scraper |   [47/100] https://www.linkedin.com/jobs/view/data-scientist-analytics-engineer-at-clarity-cubed-4370554676\n",
      "2026-02-16 20:37:32,401 | INFO    | src.scraping.linkedin_scraper |   [48/100] https://www.linkedin.com/jobs/view/data-scientist-at-zywave-4372998947\n",
      "2026-02-16 20:37:35,100 | INFO    | src.scraping.linkedin_scraper |   [49/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120827281\n",
      "2026-02-16 20:37:38,326 | INFO    | src.scraping.linkedin_scraper |   [50/100] https://www.linkedin.com/jobs/view/senior-data-scientist-at-roku-4313070387\n",
      "2026-02-16 20:37:40,989 | INFO    | src.scraping.linkedin_scraper |   [51/100] https://www.linkedin.com/jobs/view/data-scientist-i-at-oscar-health-4361047857\n",
      "2026-02-16 20:37:43,784 | INFO    | src.scraping.linkedin_scraper |   [52/100] https://www.linkedin.com/jobs/view/data-scientist-junior-at-vantor-4336714326\n",
      "2026-02-16 20:37:46,845 | INFO    | src.scraping.linkedin_scraper |   [53/100] https://www.linkedin.com/jobs/view/data-scientist-l6-games-portfolio-at-netflix-4340501540\n",
      "2026-02-16 20:37:49,534 | INFO    | src.scraping.linkedin_scraper |   [54/100] https://www.linkedin.com/jobs/view/associate-data-scientist-marketing-at-bumble-inc-4371163883\n",
      "2026-02-16 20:37:52,046 | INFO    | src.scraping.linkedin_scraper |   [55/100] https://www.linkedin.com/jobs/view/data-scientist-at-dropbox-4366774315\n",
      "2026-02-16 20:37:56,439 | INFO    | src.scraping.linkedin_scraper |   [56/100] https://www.linkedin.com/jobs/view/research-scientist-%E2%80%93-multi-modal-sensing-ai-at-bosch-usa-4363025715\n",
      "2026-02-16 20:38:00,377 | INFO    | src.scraping.linkedin_scraper |   [57/100] https://www.linkedin.com/jobs/view/data-scientist-algorithms-at-lyft-4368822147\n",
      "2026-02-16 20:38:04,369 | INFO    | src.scraping.linkedin_scraper |   [58/100] https://www.linkedin.com/jobs/view/data-scientist-fraud-at-plaid-4336983612\n",
      "2026-02-16 20:38:08,624 | INFO    | src.scraping.linkedin_scraper |   [59/100] https://www.linkedin.com/jobs/view/data-scientist-analyst-at-selby-jennings-4368688540\n",
      "2026-02-16 20:38:13,243 | INFO    | src.scraping.linkedin_scraper |   [60/100] https://www.linkedin.com/jobs/view/data-scientist-algorithms-optimization-fulfillment-at-lyft-4343356776\n",
      "2026-02-16 20:38:17,571 | INFO    | src.scraping.linkedin_scraper |   [61/100] https://www.linkedin.com/jobs/view/data-scientist-at-sprouts-farmers-market-4370453027\n",
      "2026-02-16 20:38:21,989 | INFO    | src.scraping.linkedin_scraper |   [62/100] https://www.linkedin.com/jobs/view/data-scientist-at-boston-va-research-institute-inc-bvari-4361022302\n",
      "2026-02-16 20:38:25,221 | INFO    | src.scraping.linkedin_scraper |   [63/100] https://www.linkedin.com/jobs/view/machine-learning-engineer-intern-ms-phd-2026-at-netflix-4312232372\n",
      "2026-02-16 20:38:28,617 | INFO    | src.scraping.linkedin_scraper |   [64/100] https://www.linkedin.com/jobs/view/data-scientist-product-analytics-at-meta-4120824560\n",
      "2026-02-16 20:38:31,928 | INFO    | src.scraping.linkedin_scraper |   [65/100] https://www.linkedin.com/jobs/view/data-scientist-at-validifi-4366774033\n",
      "2026-02-16 20:38:34,947 | INFO    | src.scraping.linkedin_scraper |   [66/100] https://www.linkedin.com/jobs/view/data-scientist-strategic-intelligence-risk-at-openai-4308316149\n",
      "2026-02-16 20:38:37,552 | INFO    | src.scraping.linkedin_scraper |   [67/100] https://www.linkedin.com/jobs/view/data-scientist-at-dw-sisters-llc-4373803233\n",
      "2026-02-16 20:38:40,341 | INFO    | src.scraping.linkedin_scraper |   [68/100] https://www.linkedin.com/jobs/view/data-scientist-remote-at-lensa-4373526330\n",
      "2026-02-16 20:38:43,267 | INFO    | src.scraping.linkedin_scraper |   [69/100] https://www.linkedin.com/jobs/view/data-scientist-at-wpromote-4343510518\n",
      "2026-02-16 20:38:46,159 | INFO    | src.scraping.linkedin_scraper |   [70/100] https://www.linkedin.com/jobs/view/data-scientist-at-boston-va-research-institute-inc-bvari-4360545316\n",
      "2026-02-16 20:38:49,539 | INFO    | src.scraping.linkedin_scraper |   [71/100] https://www.linkedin.com/jobs/view/staff-data-scientist-marketing-at-asana-4318911714\n",
      "2026-02-16 20:38:52,093 | INFO    | src.scraping.linkedin_scraper |   [72/100] https://www.linkedin.com/jobs/view/data-scientist-at-kforce-inc-4369987096\n",
      "2026-02-16 20:38:54,591 | INFO    | src.scraping.linkedin_scraper |   [73/100] https://www.linkedin.com/jobs/view/data-scientist-i-at-worldpay-4372205716\n",
      "2026-02-16 20:38:57,620 | INFO    | src.scraping.linkedin_scraper |   [74/100] https://www.linkedin.com/jobs/view/data-scientist-at-alexander-chapman-4367472299\n",
      "2026-02-16 20:39:00,360 | INFO    | src.scraping.linkedin_scraper |   [75/100] https://www.linkedin.com/jobs/view/business-data-scientist-google-cloud-security-strategy-at-google-4370409239\n",
      "2026-02-16 20:39:03,453 | INFO    | src.scraping.linkedin_scraper |   [76/100] https://www.linkedin.com/jobs/view/product-data-scientist-at-avepoint-4323248474\n",
      "2026-02-16 20:39:06,278 | INFO    | src.scraping.linkedin_scraper |   [77/100] https://www.linkedin.com/jobs/view/data-scientist-at-citadel-securities-4264412194\n",
      "2026-02-16 20:39:09,730 | INFO    | src.scraping.linkedin_scraper |   [78/100] https://www.linkedin.com/jobs/view/director-data-scientist-predictive-agentic-ai-at-symphonyai-4371016799\n",
      "2026-02-16 20:39:12,339 | INFO    | src.scraping.linkedin_scraper |   [79/100] https://www.linkedin.com/jobs/view/data-scientist-product-education-data-science-at-google-4371174701\n",
      "2026-02-16 20:39:15,489 | INFO    | src.scraping.linkedin_scraper |   [80/100] https://www.linkedin.com/jobs/view/data-scientist-at-eleve-talent-4357505302\n",
      "2026-02-16 20:39:19,441 | INFO    | src.scraping.linkedin_scraper |   [81/100] https://www.linkedin.com/jobs/view/data-scientist-at-curate-partners-4368842402\n",
      "2026-02-16 20:39:22,502 | INFO    | src.scraping.linkedin_scraper |   [82/100] https://www.linkedin.com/jobs/view/senior-data-scientist-at-hiretalent-staffing-recruiting-firm-4371074567\n",
      "2026-02-16 20:39:25,670 | INFO    | src.scraping.linkedin_scraper |   [83/100] https://www.linkedin.com/jobs/view/data-scientist-at-csg-talent-4367494187\n",
      "2026-02-16 20:39:28,777 | INFO    | src.scraping.linkedin_scraper |   [84/100] https://www.linkedin.com/jobs/view/data-scientist-marketing-at-openai-4313117330\n",
      "2026-02-16 20:39:31,616 | INFO    | src.scraping.linkedin_scraper |   [85/100] https://www.linkedin.com/jobs/view/data-scientist-subscription-analytics-at-apple-4369835279\n",
      "2026-02-16 20:39:34,266 | INFO    | src.scraping.linkedin_scraper |   [86/100] https://www.linkedin.com/jobs/view/data-scientist-at-opendoor-4319965227\n",
      "2026-02-16 20:39:37,443 | INFO    | src.scraping.linkedin_scraper |   [87/100] https://www.linkedin.com/jobs/view/data-scientist-994-at-lightcast-4356557282\n",
      "2026-02-16 20:39:39,369 | INFO    | src.scraping.linkedin_scraper |   [88/100] https://www.linkedin.com/jobs/view/data-scientist-ii-at-esri-4363156475\n",
      "2026-02-16 20:39:41,873 | INFO    | src.scraping.linkedin_scraper |   [89/100] https://www.linkedin.com/jobs/view/data-scientist-marketing-at-openai-4340958481\n",
      "2026-02-16 20:39:44,747 | INFO    | src.scraping.linkedin_scraper |   [90/100] https://www.linkedin.com/jobs/view/data-scientist-at-skybridge-aviation-4371458696\n",
      "2026-02-16 20:39:47,722 | INFO    | src.scraping.linkedin_scraper |   [91/100] https://www.linkedin.com/jobs/view/data-scientist-at-intepros-4371615335\n",
      "2026-02-16 20:39:50,263 | INFO    | src.scraping.linkedin_scraper |   [92/100] https://www.linkedin.com/jobs/view/data-scientist-level-4-at-snap-inc-4354578358\n",
      "2026-02-16 20:39:53,513 | INFO    | src.scraping.linkedin_scraper |   [93/100] https://www.linkedin.com/jobs/view/data-scientist-at-pathpoint-4372210730\n",
      "2026-02-16 20:39:57,168 | INFO    | src.scraping.linkedin_scraper |   [94/100] https://www.linkedin.com/jobs/view/data-scientist-drilling-global-energy-tech-company-at-andiamo-4362601156\n",
      "2026-02-16 20:40:03,144 | INFO    | src.scraping.linkedin_scraper |   [95/100] https://www.linkedin.com/jobs/view/data-scientist-at-sotalent-4364569938\n",
      "2026-02-16 20:40:08,024 | INFO    | src.scraping.linkedin_scraper |   [96/100] https://www.linkedin.com/jobs/view/data-scientist-at-mantra-health-4366770843\n",
      "2026-02-16 20:40:11,855 | INFO    | src.scraping.linkedin_scraper |   [97/100] https://www.linkedin.com/jobs/view/data-scientist-intern-tiktok-product-data-science-2026-summer-bs-ms-at-tiktok-4277124493\n",
      "2026-02-16 20:40:16,172 | INFO    | src.scraping.linkedin_scraper |   [98/100] https://www.linkedin.com/jobs/view/machine-learning-engineer-ml-infra-at-impax-recruitment-4371862255\n",
      "2026-02-16 20:40:20,495 | INFO    | src.scraping.linkedin_scraper |   [99/100] https://www.linkedin.com/jobs/view/full-stack-machine-learning-engineer-at-statt-4369979307\n",
      "2026-02-16 20:40:23,729 | INFO    | src.scraping.linkedin_scraper |   [100/100] https://www.linkedin.com/jobs/view/senior-data-scientist-%E2%80%93-techops-predictive-engineering-at-delta-air-lines-4370455092\n",
      "2026-02-16 20:40:27,227 | INFO    | src.scraping.linkedin_scraper | Phase 2 complete: 100/100 jobs. Quality: 67% high, 33% med, 0% low\n",
      "2026-02-16 20:40:27,228 | INFO    | src.scraping.linkedin_scraper | Phase 3 complete: 0 unique companies extracted\n",
      "2026-02-16 20:40:27,255 | INFO    | src.scraping.linkedin_scraper | Raw job records saved: c:\\top-applicant\\data/raw/jobs\\linkedin_raw_jobs_data_scientist_20260216_204027.json\n",
      "2026-02-16 20:40:27,260 | INFO    | src.pipeline | Saved scrape report: outputs/tables\\scrape_report_20260216_204027.json\n",
      "2026-02-16 20:40:27,261 | INFO    | src.pipeline | ============================================================\n",
      "2026-02-16 20:40:27,262 | INFO    | src.pipeline | PIPELINE COMPLETE\n",
      "2026-02-16 20:40:27,263 | INFO    | src.pipeline | Records: 100\n",
      "2026-02-16 20:40:27,265 | INFO    | src.pipeline | Failures: 0\n",
      "2026-02-16 20:40:27,266 | INFO    | src.pipeline | Output directory: c:\\top-applicant\\data/raw/jobs\n",
      "2026-02-16 20:40:27,267 | INFO    | src.pipeline | Log: outputs/logs\\scrape_20260216_203439.log\n",
      "2026-02-16 20:40:27,269 | INFO    | src.pipeline | ============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUCCESS: 100 raw job records captured (v1.0.0)\n",
      "Columns: 9 raw fields\n",
      "Location: c:\\top-applicant\\data/raw/jobs/\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Set working directory to project root for pipeline paths\n",
    "os.chdir(project_root)\n",
    "\n",
    "# ── Run Raw-Only Pipeline (v1.0.0) ──\n",
    "df = run_pipeline(\n",
    "    keywords=KEYWORDS,\n",
    "    location=LOCATION,\n",
    "    limit=LIMIT,\n",
    "    raw_output_dir=RAW_OUTPUT_DIR,\n",
    "    scrape_company_pages=SCRAPE_COMPANY_PAGES\n",
    ")\n",
    "\n",
    "if df is not None and not df.empty:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUCCESS: {len(df)} raw job records captured (v1.0.0)\")\n",
    "    print(f\"Columns: {len(df.columns)} raw fields\")\n",
    "    print(f\"Location: {RAW_OUTPUT_DIR}/\")\n",
    "    print(f\"{'='*60}\")\n",
    "else:\n",
    "    print(\"Pipeline returned no data. Check logs in outputs/logs/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6cf34d",
   "metadata": {},
   "source": [
    "## Inspect Raw Results\n",
    "Quick validation of captured raw data and extraction quality metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082fc25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "─── Raw Schema (v1.0.0) ───\n",
      "Total records: 100\n",
      "Total columns: 9\n",
      "\n",
      "Nested sections in each record:\n",
      "  • scrape_metadata\n",
      "  • job_identity\n",
      "  • job_card_raw\n",
      "  • job_page_raw\n",
      "  • company_info\n",
      "  • quality_tracking\n",
      "  • hashing\n",
      "\n",
      "─── Field Coverage (Raw Fields) ───\n",
      "  raw_schema_version                       100/100 (100.0%)\n",
      "  job_card_raw                             100/100 (100.0%)\n",
      "  job_page_raw                             100/100 (100.0%)\n",
      "  hashing                                  100/100 (100.0%)\n",
      "\n",
      "─── Extraction Quality ───\n",
      "  High quality:    55 ( 55.0%)\n",
      "  Medium quality:  45 ( 45.0%)\n",
      "  Low quality:      0 (  0.0%)\n",
      "\n",
      "─── Sample Record Keys (Top Level) ───\n",
      "  (Inspect via DataFrame directly)\n"
     ]
    }
   ],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"─── Raw Schema (v1.0.0) ───\")\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Total columns: {len(df.columns)}\")\n",
    "    \n",
    "    # Show nested structure\n",
    "    print(\"\\nNested sections in each record:\")\n",
    "    nested_sections = [\n",
    "        'scrape_metadata', 'job_identity', 'job_card_raw', 'job_page_raw',\n",
    "        'company_info', 'quality_tracking', 'hashing'\n",
    "    ]\n",
    "    for section in nested_sections:\n",
    "        if section in df.columns or (isinstance(df.iloc[0], dict) and section in df.iloc[0]):\n",
    "            print(f\"  • {section}\")\n",
    "    \n",
    "    # Field coverage\n",
    "    print(\"\\n─── Field Coverage (Raw Fields) ───\")\n",
    "    coverage_cols = [col for col in df.columns if 'raw' in col or 'hash' in col]\n",
    "    if coverage_cols:\n",
    "        for col in coverage_cols[:15]:  # Show first 15\n",
    "            non_null = df[col].notna().sum()\n",
    "            pct = non_null / len(df) * 100\n",
    "            print(f\"  {col:40s} {non_null:3d}/{len(df)} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    print(\"\\n─── Extraction Quality ───\")\n",
    "    if 'quality_tracking' in df.columns or any('extraction_quality' in str(col) for col in df.columns):\n",
    "        try:\n",
    "            # Try to extract quality data from nested structure\n",
    "            quality_stats = {\"high\": 0, \"medium\": 0, \"low\": 0}\n",
    "            for record in df.itertuples():\n",
    "                if hasattr(record, 'quality_tracking') and isinstance(record.quality_tracking, dict):\n",
    "                    qual = record.quality_tracking.get('extraction_quality', 'unknown')\n",
    "                    if qual in quality_stats:\n",
    "                        quality_stats[qual] += 1\n",
    "            \n",
    "            if sum(quality_stats.values()) > 0:\n",
    "                total = sum(quality_stats.values())\n",
    "                print(f\"  High quality:   {quality_stats['high']:3d} ({quality_stats['high']/total*100:5.1f}%)\")\n",
    "                print(f\"  Medium quality: {quality_stats['medium']:3d} ({quality_stats['medium']/total*100:5.1f}%)\")\n",
    "                print(f\"  Low quality:    {quality_stats['low']:3d} ({quality_stats['low']/total*100:5.1f}%)\")\n",
    "        except:\n",
    "            print(\"  (Quality metrics not available in current format)\")\n",
    "    \n",
    "    # Sample record structure\n",
    "    print(\"\\n─── Sample Record Keys (Top Level) ───\")\n",
    "    sample = df.iloc[0]\n",
    "    if isinstance(sample, dict):\n",
    "        for k in list(sample.keys())[:10]:\n",
    "            print(f\"  • {k}\")\n",
    "    else:\n",
    "        print(\"  (Inspect via DataFrame directly)\")\n",
    "else:\n",
    "    print(\"No data available. Run the pipeline cell above first.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8bfd72",
   "metadata": {},
   "source": [
    "## Data Quality & Next Steps\n",
    "Summary of data collection and recommendations for preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c270c183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "─── Data Collection Summary ───\n",
      "Records collected: 100\n",
      "Schema version: 1.0.0 (frozen)\n",
      "Company pages scraped: False\n",
      "\n",
      "─── Next Steps ───\n",
      "1. Raw data saved to: c:\\top-applicant\\data/raw/jobs/\n",
      "2. Load with:\n",
      "     import json\n",
      "     # Find latest file in c:\\top-applicant\\data/raw/jobs/\n",
      "     with open('data/raw/linkedin_raw_jobs_<timestamp>.json') as f:\n",
      "         raw_jobs = json.load(f)\n",
      "3. Process raw fields using preprocessing pipelines\n",
      "4. Content hashing enables change detection across runs\n",
      "\n",
      "─── Raw Fields Available ───\n",
      "Job records include:\n",
      "  • Scrape metadata (timestamp, user agent, keywords)\n",
      "  • Job identity (URL, hashed job ID)\n",
      "  • Job card fields (title, company, location, posted date)\n",
      "  • Full job page (description text + HTML, salary, applicants, criteria)\n",
      "  • Embedded data (JSON-LD, job-specific JSON)\n",
      "  • Extraction quality (high/medium/low, selector hits, retry count)\n",
      "  • Content hashes (for deduplication and change tracking)\n",
      "\n",
      "─── Data Preservation ───\n",
      "✓ All raw data is immutable (v1.0.0 schema frozen)\n",
      "✓ Content hashing prevents accidental modifications\n",
      "✓ Multiple runs can be compared for changes\n",
      "✓ Archive in data/raw/ for historical tracking\n"
     ]
    }
   ],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"─── Data Collection Summary ───\")\n",
    "    print(f\"Records collected: {len(df)}\")\n",
    "    print(f\"Schema version: 1.0.0 (frozen)\")\n",
    "    print(f\"Company pages scraped: {SCRAPE_COMPANY_PAGES}\")\n",
    "    \n",
    "    print(\"\\n─── Next Steps ───\")\n",
    "    print(f\"1. Raw data saved to: {RAW_OUTPUT_DIR}/\")\n",
    "    print(f\"2. Load with:\")\n",
    "    print(f\"     import json\")\n",
    "    print(f\"     # Find latest file in {RAW_OUTPUT_DIR}/\")\n",
    "    print(f\"     with open('data/raw/linkedin_raw_jobs_<timestamp>.json') as f:\")\n",
    "    print(f\"         raw_jobs = json.load(f)\")\n",
    "    print(f\"3. Process raw fields using preprocessing pipelines\")\n",
    "    print(f\"4. Content hashing enables change detection across runs\")\n",
    "    \n",
    "    print(\"\\n─── Raw Fields Available ───\")\n",
    "    print(\"Job records include:\")\n",
    "    print(\"  • Scrape metadata (timestamp, user agent, keywords)\")\n",
    "    print(\"  • Job identity (URL, hashed job ID)\")\n",
    "    print(\"  • Job card fields (title, company, location, posted date)\")\n",
    "    print(\"  • Full job page (description text + HTML, salary, applicants, criteria)\")\n",
    "    print(\"  • Embedded data (JSON-LD, job-specific JSON)\")\n",
    "    print(\"  • Extraction quality (high/medium/low, selector hits, retry count)\")\n",
    "    print(\"  • Content hashes (for deduplication and change tracking)\")\n",
    "    \n",
    "    if SCRAPE_COMPANY_PAGES:\n",
    "        print(\"\\n  + Company records include:\")\n",
    "        print(\"    • Company metadata (identity, URLs)\")\n",
    "        print(\"    • About section (text + HTML)\")\n",
    "        print(\"    • Company facts (industry, size, HQ, type, specialties)\")\n",
    "        print(\"    • Timestamps (first/last seen)\")\n",
    "    \n",
    "    print(\"\\n─── Data Preservation ───\")\n",
    "    print(\"✓ All raw data is immutable (v1.0.0 schema frozen)\")\n",
    "    print(\"✓ Content hashing prevents accidental modifications\")\n",
    "    print(\"✓ Multiple runs can be compared for changes\")\n",
    "    print(\"✓ Archive in data/raw/ for historical tracking\")\n",
    "    \n",
    "else:\n",
    "    print(\"No data available. Run the pipeline cell to collect data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75338065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
